{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUX78DM7n9T"
      },
      "source": [
        "# Temas Tratados en el Trabajo Práctico 1\n",
        "\n",
        "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
        "\n",
        "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
        "\n",
        "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
        "\n",
        "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
        "\n",
        "* Caracterización del Entorno de Trabajo.\n",
        "\n",
        "# Anotaciones\n",
        "\n",
        "# Ejercicios Teóricos\n",
        "\n",
        "1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente.\n",
        "\n",
        "* La inteligencia natural es la capacidad de procesar información, adaptarse a nuevos contextos, resolver problemas y tomar decisiones. Es innato al proceso u objeto de estudio, por ejemplo la inteligencia de la naturaleza para llevar a cabo los procesos naturales.\n",
        "* El concepto de inteligencia artificial se le atribuye a aquel objeto o proceso al que se le han desarrollado mecanismos para cumplir un fin, por ejemplo, una vela se apaga cuando se derrite hasta cierto punto determinado previamente.\n",
        "* Un agente es aquel ente que toma variables de entrada desde el entorno a través de sensores, procesa los datos y en la salida entrega un resultado a través de actuadores.\n",
        "\n",
        "2. ¿Qué es un agente racional?\n",
        "\n",
        "Un agente racional es un objeto que tiene la capacidad de percibir su entorno y actuar sobre él para cumplir cierto objetivo con alguna medida de rendimiento asociada. También puede tomar decisiones y algunos tienen la capacidad de aprender.\n",
        "\n",
        "3. ¿Un agente es siempre una computadora?\n",
        "\n",
        "No, un agente puede ser cualquier objeto del mundo real que pueda realizar tareas o cumplir un objetivo a través diversos mecanismos, no computarizados necesariamente.\n",
        "\n",
        "4. Defina Omnisciencia, Aprendizaje y Autonomía.\n",
        "\n",
        "* Omnisciencia es la capacidad de saber o conocer absolutamente todo lo real y posible.\n",
        "* El aprendizaje es la capacidad de un objeto, con una medida de rendimiento asociada que, a través del procesamiento de información y de repetir patrones, puede adquirir conocimiento nuevo con el cual realizar una acción sobre el entorno, con la intención de mejorar u optimizar el mismo.\n",
        "* Autonomía es la capacidad de un objeto inteligente de llevar a cabo una acción por sí mismo, sin necesidad de aprendizaje.\n",
        "\n",
        "5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría.\n",
        "\n",
        "* Reactivos\n",
        "* Reactivo simple: en base a una percepción, tiene una salida. Por ejemplo, un despertador: se programa que suene a una hora determinada y suena a esa hora.\n",
        "* Basados en modelos: A partir de una entrada, evalúa su estado y en función de esto, ejecuta una salida. Modelo matemático o discreto, se puede diagramar y se puede demostrar.\n",
        "\n",
        "* Con memoria o complejos\n",
        "* Basados en objetivos: se establece una medida de rendimiento (objetivo) no nos interesan los mecanismos intermedios, solo que logre el objetivo en la mejor manera posible (optimizando la medida de rendimiento).\n",
        "* Basados en utilidad: En el caso anterior puede pasar que la medida de rendimiento óptima sea muy cara. Por eso, en estos agentes, se hace una ponderación sobre la medida de rendimiento y se logra el objetivo de la manera más cómoda posible. La utilidad se la da el usuario.\n",
        "* Agentes que aprenden: por definición, tienen que tener la capacidad de aprender. La particularidad principal es que tienen una etapa de entrenamiento donde nosotros ajustamos los parámetros. Y, por otro lado, se planea una segunda etapa, cuando ya terminó el entrenamiento, pasa a actuar como un agente reactivo basado en modelos. Puede terminar o no la etapa de entrenamiento. Modelos no lineales, no se pueden conceptualizar matemáticamente o diagramar, a diferencia de los agentes basados en modelos.\n",
        "\n",
        "6. Para los siguientes entornos de trabajo indique sus **propiedades**:\n",
        "\n",
        "        a. Una partida de ajedrez.\n",
        "\n",
        "        Es totalmente observable si tiene todos los sensores suficientes para lograr el objetivo.\n",
        "        Es estocástico porque la siguiente acción va a ser determinada probabilísticamente a partir de la acción actual.\n",
        "        Es secuencial porque el estado siguiente va a depender de la acción actual.\n",
        "        Es estático porque mientras está razonando en un turno, el entorno no puede cambiar.\n",
        "        Es discreto porque el agente puede hacer una cantidad finita de acciones.\n",
        "        Es multiagente porque el segundo agente afecta la respuesta del primero.\n",
        "\n",
        "        b. Un partido de baloncesto.\n",
        "\n",
        "        Totalmente observable porque considero que el juego se ve externamente con cámaras que pueden tomar todos los puntos de vista de la cancha.\n",
        "        Es estocástico porque no está determinada cada jugada durante el partido.\n",
        "        Es episódico porque el objetivo es meter un gol, sin importar las jugadas que se hayan hecho en cada momento previo.\n",
        "        Es dinámico porque las jugadas van cambiando en todo momento y las decisiones del agente se verán afectadas instante a instante.\n",
        "        Es continuo porque existen infinitas percepciones y acciones por parte del agente.\n",
        "        Es multiagente porque la decisión que tome el agente depende de la decisión del contrincante.\n",
        "\n",
        "        c. El juego Pacman.\n",
        "\n",
        "        Es totalmente observable porque desde el punto de vista del jugador se puede observar todo el tablero de juego así como las posiciones de los fantasmas.\n",
        "        Es estocástico por la incertidumbre de cuál va a ser el movimiento de los fantasmas, que va a condicionar el movimiento del jugador.\n",
        "        Es secuencial porque la decisión de movimiento va a depender de los movimientos previos que hayan ocurrido.\n",
        "        Es dinámico porque el entorno cambia mientras se toma la decisión sobre cuál va a ser el próximo movimiento.\n",
        "        Es continuo porque el jugador puede decidir entre infinitos movimientos dentro del tablero de juego.\n",
        "        Es multiagente porque las acciones de agentes como los fantasmas influyen en las acciones del jugador.\n",
        "        \n",
        "\n",
        "        d. El truco.\n",
        "\n",
        "        Es parcialmente observable porque el jugador tiene conocimiento de las cartas que tiene en su mano pero no de las cartas de su contrincante.\n",
        "        Es determinista porque las jugadas que se pueden hacer con las cartas que le ha tocado son limitadas y ya están dadas para un determinado escenario de juego.\n",
        "        Es secuencial ya que el jugador decide qué carta de su mano jugar de acuerdo a cuál es la jugada que hizo su oponente.\n",
        "        Es estático puesto que una vez repartidas las cartas ya no se pueden cambiar, por lo que mientras el jugador decide qué carta jugar,su oponente no puede cambiar su juego.\n",
        "        Es discreto porque las opciones de juego son finitas.\n",
        "        Es multiagente porque las decisiones de juego de cada jugador influyen en la del otro.\n",
        "\n",
        "        e. Las damas.\n",
        "\n",
        "        Es totalmente observable ya que el jugador puede ver las posiciones que ocupan todas las fichas en el tablero.\n",
        "        Es determinista ya que cada ficha tiene unas posibilidades de movimiento ya determinada\n",
        "        Es secuencial porque el movimiento de las fichas va a depender de los movimientos previos que se realizaron tanto propios como del oponente\n",
        "        Es estático porque a la hora de jugar el turno el tablero no va a cambiar, es decir el oponente no puede realizar movimientos.\n",
        "        Es discreto por lo limitado de los movimientos que pueden realizar las fichas.\n",
        "        Es multiagente al tener 2 jugadores que influyen en las decisiones del otro.\n",
        "\n",
        "        f. El juego tres en raya.\n",
        "\n",
        "        Es totalmente observable, se puede ver el tablero completo durante el juego. \n",
        "        Es determinista ya que los movimientos que se pueden realizar son conocidos y ya están determinados.\n",
        "        Es secuencial siendo las acciones previas del otro jugador las que condicionan los movimientos.\n",
        "        Es estático ya que las fichas no cambian de posición mientras el jugador decide su movimiento.\n",
        "        Es discreto porque son limitados los movimientos que puede realizar cada jugador.\n",
        "        Es multiagente con dos jugadores que condicionan el juego del otro.\n",
        "\n",
        "        g. Un jugador de Pokémon Go.\n",
        "\n",
        "        Es parcialmente observable porque un jugador puede observar e interactuar con la parte del mapa en la que se encuentra ubicado geográficamente pero no puede conocer qué pokemones hay en otros lugares fuera de su rango de acción.\n",
        "        Es estocástico porque hay bastante azar en el juego y ante una misma acción de lucha contra un pokémon pueden haber distintos resultados.\n",
        "        Es episódico porque al encontrarse un pokémon el jugador puede luchar con él o no sin importar las luchas previas que haya tenido con otros pokemones. \n",
        "        Es dinámico dado que el entorno puede cambiar, los pokemones pueden desaparecer si se demora mucho en intentar capturarlo.\n",
        "        Es continuo porque el jugador puede realizar infinitos movimientos, siendo el mapa de realidad aumentada.\n",
        "        Es multiagente ya que las acciones de los pokemones condicionan las decisiones del jugador.\n",
        "\n",
        "        h. Un robot explorador autónomo de Marte.\n",
        "\n",
        "        Es totalmente observable siempre que cuente con los sensores para poder hacer un panorama completo del terreno en el que se encuentra.\n",
        "        Es estocástico ya que no se puede conocer de antemano con qué se va a encontrar una vez llegado a Marte y cuales van a ser los movimientos que deba realizar.\n",
        "        Es secuencial siendo sus acciones dependientes de las anteriores\n",
        "        Es dinámico porque su entorno puede cambiar influyendo en sus acciones.\n",
        "        Es continuo por la diversidad de movimientos que puede realizar.\n",
        "        Es individual ya que no hay otro agente interactuando con el que pueda modificar sus acciones más que el entorno mismo.\n",
        "\n",
        "7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
        "\n",
        "        a. Crucigrama.\n",
        "        Agente: persona.\n",
        "        Medidas de rendimiento: menor tiempo de llenado, precisión en que cada letra coincida en la casilla correspondiente y que cada palabra cumpla con la definición para ese conjunto de casillas.\n",
        "        Entorno: cantidad de casillas vacías, casillas ocupadas, letras que ya están definidas y que no se pueden modificar, definiciones para las palabras para llenar el crucigrama, persona que llena el crucigrama, teclado, pantalla que renderiza el crucigrama.\n",
        "        Actuadores: manos.\n",
        "        Sensores: ojos.\n",
        "\n",
        "        b. Taxi circulando.\n",
        "        Agente: taxi autónomo\n",
        "        Medidas de rendimiento: rapidez, distancia óptima, seguridad del pasajero y de todo su entorno.\n",
        "        Entorno: peatones, otros vehículos, obstáculos, animales, carteles y señales de tránsito, delimitadores de carriles, guardarrail, clientes, calles, avenidas y rutas.\n",
        "        Actuadores: dirección, acelerador, freno, bocina, luces y sintetizador de voz.\n",
        "        Sensores: velocímetro, GPS, tacómetro, sensores del motor, cámaras dirigidas sonares para detectar distancias y micrófono.\n",
        "\n",
        "        c. Robot clasificador de piezas.\n",
        "        Agente: robot.\n",
        "        Medidas de rendimiento: rapidez, precisión en el movimiento y en la clasificación, y delicadeza para tomar las piezas.\n",
        "        Entorno: posición relativa entre el robot y la pieza, posición de homing, posición inicial y final de la pieza, material de la pieza, criterio de clasificación y superficie donde se depositan las piezas clasificadas.\n",
        "        Actuadores: brazo robótico, motores, drivers, efector final.\n",
        "        Sensores: cámaras, sensores de proximidad, sensores de fuerza y torque, encoders, sensores de presión, sensores táctiles.\n",
        "\n",
        "# Ejercicios Prácticos\n",
        "\n",
        "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "    Rendimiento: que el programa sea capaz de cumplir las reglas.\n",
        "    Entorno: celdas discretas, blancas y negras, cuadrícula bidimensional, la hormiga ocupa una celda y se mueve de a una celda ortogonalmente (si el blanca gira en tal sentido).\n",
        "    Sensores: color de la celda y dirección.\n",
        "    Actuadores: cambiar color de la celda, girar en algún sentido, avance.\n",
        "\n",
        "    Propiedades del entorno:\n",
        "    Es parcialmente observable porque la hormiga sólo ve en una dirección.\n",
        "    Es determinista porque se conoce su comportamiento a partir del color de las celdas.\n",
        "    Es secuencial porque las acciones previas sí afectan a las acciones posteriores.\n",
        "    Es estático porque el entorno no cambia cuando la hormiga está ejecutando una acción. Si la celda es blanca, lo seguirá siendo hasta que la hormiga la cambie.\n",
        "    Es discreto porque existe un número concreto de percepciones y acciones.\n",
        "    Es un agente individual.\n",
        "\n",
        "    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?\n",
        "    * La avenida.\n",
        "    \n",
        "\n",
        "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
        "\n",
        "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
        "\n",
        "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
        "\n",
        "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "    Rendimiento: que se cumplan las reglas\n",
        "    Entorno: casillas que representan las células, que pueden estar vivas o muertas\n",
        "    Actuadores: que permiten que se produzca el nacimiento o fallecimiento de una célula de acuerdo a las condiciones de su entorno, siguiendo las reglas.\n",
        "    Sensores: aquellos que detecten el estado de las 8 células vecinas y así saber si la célula permanece en el estado que está o si se produce un nacimiento o fallecimiento.\n",
        "\n",
        "    Propiedades del entorno:\n",
        "    Es parcialmente observable ya que una célula en particular sólo puede conocer el estado de las 8 adyacentes a ella pero no puede conocer el estado de todas las células.\n",
        "    Es determinista porque los posibles estados de las células quedan totalmente determinados por las reglas.\n",
        "    Es secuencial ya que el estado que adopten las células va a depender de los estados anteriores.\n",
        "    Es estático porque las células vecinas no van a cambiar de estado en lo que se determina el estado de una célula particular.\n",
        "    Es discreto porque las opciones de cambio que tiene la célula es limitada, se mantiene viva, nace o muere.\n",
        "    Es multiagente porque los estados que adoptan las células vecinas influyen en el estado de una célula particular.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Hormiga de Langton\n",
        "\n",
        "import pygame as pg  # Importo la librería Pygame para crear la ventana y dibujar la hormiga\n",
        "from collections import deque  # Importo 'deque' que es una cola doblemente enlazada, me permite agregar y quitar elementos de ambos extremos.\n",
        "# La usamos para manejar de forma eficiente las rotaciones de la hormiga ya que tiene el método 'rotate' que mueve los elementos de la colección\n",
        "# hacia la derecha o izquierda por un número determinado de posiciones\n",
        "\n",
        "class Ant:\n",
        "    def __init__(self, app, pos, color):\n",
        "        # Inicializo la hormiga con la aplicación, la posición inicial y el color\n",
        "        self.app = app  # Referencia a la aplicación principal\n",
        "        self.color = color  # Color de la hormiga\n",
        "        self.x, self.y = pos  # Coordenadas iniciales de la hormiga\n",
        "        self.increments = deque([(1, 0), (0, 1), (-1, 0), (0, -1)])  # Cola que maneja las direcciones (derecha, abajo, izquierda, arriba)\n",
        "        self.history = deque(maxlen=1000)  # Guardo los últimos 1000 estados para detectar patrones repetitivos\n",
        "        self.avenue_found = False  # Indica si la hormiga ya encontró la avenida\n",
        "\n",
        "    def run(self):\n",
        "        # Guardo el estado actual (posición y dirección) de la hormiga en la historia\n",
        "        state = (self.x, self.y, tuple(self.increments))\n",
        "        self.history.append(state)  # Agrego el estado actual al historial\n",
        "        \n",
        "        # Si aún no se ha encontrado la avenida, busco si el patrón actual se repite\n",
        "        if not self.avenue_found and self.history.count(state) > 10:  # Si el estado actual aparece más de 10 veces, considero que encontró la avenida\n",
        "            self.app.iterations_until_avenue = self.app.iterations  # Registro cuántas iteraciones tomó encontrar la avenida\n",
        "            self.avenue_found = True  # Marco que se encontró la avenida\n",
        "            print(f\"La hormiga ha encontrado la avenida después de {self.app.iterations_until_avenue} iteraciones.\")\n",
        "        \n",
        "        # Manejo el cambio de color de la celda y el movimiento de la hormiga\n",
        "        value = self.app.grid[self.y][self.x]  # Obtengo el valor de la celda actual (True o False)\n",
        "        self.app.grid[self.y][self.x] = not value  # Cambio el color de la celda (de blanco a negro o viceversa)\n",
        "        \n",
        "        # Dibujo la celda con el nuevo color\n",
        "        SIZE = self.app.CELL_SIZE\n",
        "        rect = self.x * SIZE, self.y * SIZE, SIZE - 1, SIZE - 1\n",
        "        if value:\n",
        "            pg.draw.rect(self.app.screen, pg.Color('white'), rect)  # Si era blanco, ahora será negro\n",
        "        else:\n",
        "            pg.draw.rect(self.app.screen, self.color, rect)  # Si era negro, ahora será blanco\n",
        "        \n",
        "        # Rotación de la hormiga según el color de la celda (blanco: derecha, negro: izquierda)\n",
        "        self.increments.rotate(1) if value else self.increments.rotate(-1)\n",
        "        dx, dy = self.increments[0]  # Obtengo la nueva dirección de la hormiga\n",
        "        self.x = (self.x + dx) % self.app.COLS  # Actualizo la posición de la hormiga en X (asegurando que no salga de la cuadrícula)\n",
        "        self.y = (self.y + dy) % self.app.ROWS  # Actualizo la posición de la hormiga en Y (asegurando que no salga de la cuadrícula)\n",
        "\n",
        "        # Si la hormiga choca con el borde, detengo el programa\n",
        "        if self.x == 0 or self.x == self.app.COLS - 1 or self.y == 0 or self.y == self.app.ROWS - 1:\n",
        "            pg.quit()  # Cierro Pygame\n",
        "            exit()  # Salgo del programa\n",
        "\n",
        "class App:\n",
        "    def __init__(self, WIDTH=900, HEIGHT=500, CELL_SIZE=4):\n",
        "        # Inicializo la aplicación Pygame\n",
        "        pg.init()\n",
        "        self.screen = pg.display.set_mode([WIDTH, HEIGHT])  # Configuro la ventana de Pygame\n",
        "        self.clock = pg.time.Clock()  # Creo un reloj para controlar la velocidad de la simulación\n",
        "\n",
        "        self.CELL_SIZE = CELL_SIZE  # Tamaño de cada celda\n",
        "        self.ROWS, self.COLS = HEIGHT // CELL_SIZE, WIDTH // CELL_SIZE  # Número de filas y columnas basado en el tamaño de las celdas\n",
        "        self.grid = [[0 for col in range(self.COLS)] for row in range(self.ROWS)]  # Creo la cuadrícula donde se moverá la hormiga\n",
        "\n",
        "        # Creo una instancia de la hormiga en el centro de la cuadrícula\n",
        "        self.ant = Ant(app=self, pos=[self.COLS // 2, self.ROWS // 2], color=pg.Color('black'))\n",
        "        self.iterations = 0  # Inicializo el contador de iteraciones totales\n",
        "        self.iterations_until_avenue = 0  # Inicializo el contador de iteraciones hasta encontrar la avenida\n",
        "    \n",
        "    def run(self):\n",
        "        # Bucle principal de la aplicación\n",
        "        while True:\n",
        "            self.ant.run()  # Ejecuto la lógica de la hormiga en cada iteración\n",
        "            self.iterations += 1  # Incremento el contador de iteraciones\n",
        "\n",
        "            [exit() for i in pg.event.get() if i.type == pg.QUIT]  # Permito salir del programa si se cierra la ventana\n",
        "            pg.display.flip()  # Actualizo la pantalla para mostrar los cambios\n",
        "            self.clock.tick()  # Para mantener la simulación a 60 FPS (frames por segundo) poner 60 como parámetro\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app = App()  # Creo una instancia de la aplicación\n",
        "    app.run()  # Inicio la simulación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### El juego de la vida\n",
        "\n",
        "import time\n",
        "import os\n",
        "os.system(\"\")\n",
        "\n",
        "Cw=20\n",
        "Ch=20\n",
        "Lienzo=[' ' for _ in range((Cw*2+1)*Ch)] #Creamos el array de caracteres sobre el que vamos a pintar\n",
        "for i in range(Ch):\n",
        "\tLienzo[Cw*2*(i+1)]='\\n'\n",
        "\n",
        "Lienzo_base=Lienzo.copy() #Una copia a la que vamos a volver tras cada frame\n",
        "\n",
        "def pintar_pixel(x,y,color_p): #pinta los pixeles del lienzo usando codigos de escape ANSI\n",
        "\tglobal Lienzo\n",
        "\tcolor = color_p*7+40 #Si es 1 es blanco, si es 0 es negro\n",
        "\tpos = y*Cw*2+x*2\n",
        "\tLienzo[pos]=Lienzo[pos+1]=\"\\x1b[\"+str(color)+\"m \\x1b[0m\"\n",
        "\n",
        "celulas_base = [[0 for i in range(Cw*2)] for j in range(Ch)]\n",
        "celulas=celulas_base.copy()\n",
        "live = []\n",
        "celulas[5][7:10]=[1,1,1] #3 celulas iniciales para probar\n",
        "\n",
        "def step(live):\n",
        "\tglobal celulas\n",
        "\tlive.clear()\n",
        "\t\n",
        "\t#recorremos todas las celulas, si una celula en el siguiente frame debería estar viva agregamos sus coordenadas a la lista live\n",
        "\tfor x in range(Cw):\n",
        "\t\tfor y in range(Ch):\n",
        "\t\t\tcelula = celulas[y][x]\n",
        "\t\t\tn = get_neighbors(x,y)\n",
        "\t\t\tif celula==1:\n",
        "\t\t\t\tif n==2 or n==3:\n",
        "\t\t\t\t\tlive.append([x,y]) #si la celula está viva y tiene 2 o 3 vecinos vivos sigue viva\n",
        "\t\t\telif n==3:\n",
        "\t\t\t\tlive.append([x,y]) #si una celula muerta tiene 3 vecinos vivos cobra vida\n",
        "\t#celulas=celulas_base.copy() #borramos los datos del frame previo\n",
        "\tfor j in range(len(celulas)):\n",
        "\t\tfor i in range(len(celulas[j])):\n",
        "\t\t\tcelulas[j][i]=0\n",
        "\t\n",
        "\tfor cell in live:\n",
        "\t\tcelulas[cell[1]][cell[0]]=1 #en todas las celulas que deberían estar vivas les escribimos 1\n",
        "\n",
        "\n",
        "def get_neighbors(x, y): #Obtiene el número de vecinos vivos rodeando a una celula\n",
        "\tn = 0\n",
        "\tfor i in range(x-1,x+2):\n",
        "\t\tfor j in range(y-1,y+2):\n",
        "\t\t\tif not(i==x and j==y) and (Cw>i>=0 and Ch>j>=0):\n",
        "\t\t\t\tif celulas[j][i]==1: n+=1  #;print(str(i)+\" \"+str(j))\n",
        "\treturn n\n",
        "\n",
        "def renderizar():  #pinta todas las celulas vivas, convierte el Lienzo en un string y lo imprime \n",
        "\tglobal Lienzo\n",
        "\t\n",
        "\tfor cell in live:\n",
        "\t\tpintar_pixel(cell[0],cell[1],1)\n",
        "\trend=\"\".join(Lienzo)\n",
        "\tprint(rend)\n",
        "\n",
        "for i in range(10):\n",
        "\tstep(live)\n",
        "\trenderizar()\n",
        "\tLienzo=Lienzo_base.copy() #limpiamos el Lienzo después de cada frame.\n",
        "\ttime.sleep(0.5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcAF__NmgG5"
      },
      "source": [
        "# Bibliografía\n",
        "\n",
        "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
        "\n",
        "[Poole, D. & Mackworth, A. (2017) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (2a Ed.) Vancouver, Canada](https://artint.info/3e/html/ArtInt3e.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
